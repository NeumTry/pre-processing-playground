{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from langchain.docstore.document import Document \n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Define the columns we want to embed vs which ones we want in metadata\n",
    "columns_to_emebd = [\"<ARRAY OF FIELDS TO EMBED>\"]\n",
    "columns_to_metadata = [\"<ARRAY OF FIELDS FOR METADATA>\"]\n",
    "\n",
    "\n",
    "# Process the CSV into the embedable content vs the metadata and put it into Document format so that we can chunk it into pieces.\n",
    "docs = []\n",
    "with open('<PATH TO CSV>', newline=\"\", encoding='utf-8-sig') as csvfile:\n",
    "    csv_reader = csv.DictReader(csvfile)\n",
    "    for i, row in enumerate(csv_reader):\n",
    "        to_metadata = {col: row[col] for col in columns_to_metadata if col in row}\n",
    "        values_to_embed = {k: row[k] for k in columns_to_emebd if k in row}\n",
    "        to_embed = \"\\n\".join(f\"{k.strip()}: {v.strip()}\" for k, v in values_to_embed.items())\n",
    "        newDoc = Document(page_content=to_embed, metadata=to_metadata)\n",
    "        docs.append(newDoc)\n",
    "\n",
    "# Lets split the document using Chracter splitting. \n",
    "splitter = CharacterTextSplitter(separator = \"\\n\",\n",
    "                                chunk_size=500, \n",
    "                                chunk_overlap=0,\n",
    "                                length_function=len)\n",
    "documents = splitter.split_documents(docs)\n",
    "\n",
    "# Generate embeddings from documents and store in a vector database\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "db = Chroma.from_documents(documents, OpenAIEmbeddings())\n",
    "\n",
    "# Query the vector database for information.\n",
    "query = \"<QUERY FOR DATA>\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "\n",
    "metadata_field_info = [\n",
    "    # Add Attriute descriptions in the following format\n",
    "    # AttributeInfo(\n",
    "    #     name=\"<METADATA NAME>\",\n",
    "    #     description=\"<METADATA DESCRIPTION>\",\n",
    "    #     type=\"<TYPE>\",\n",
    "    # ),\n",
    "]\n",
    "\n",
    "document_content_description = \"<DESCRIPTION FOR DATA SET>\"\n",
    "llm = OpenAI(temperature=0)\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm, db, document_content_description, metadata_field_info, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.get_relevant_documents(\"expensive heart monitor\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
